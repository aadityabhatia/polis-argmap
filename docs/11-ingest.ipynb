{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Data Ingestion\n",
    "author: Sonny Bhatia\n",
    "description: Read Polis data, calculate embeddings, and store in Polars Dataframe\n",
    "image: /images/11-ingest.webp\n",
    "date: 2024-03-01\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polis datasets are publicly available at [github.com/compdemocracy/openData](https://github.com/compdemocracy/openData). We download these datasets and read the CSV files using [Polars DataFrame library](https://docs.pola.rs/). Once we have the data available in our Python environment, we use [Sentence Transformers](https://www.sbert.net/) to compute embeddings for each comment in the dataset and store that alongside the original data in our DataFrame. Then we save the DataFrame to a parquet file for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WhereIsAI/UAE-Large-V1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "from argmap.dataModel import Summary, Comments\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.getenv('EMBED_MODEL_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Embedding Model\n",
    "\n",
    "Here we consider several embedding models based on [HuggingFace Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard). The following models are considered:\n",
    "\n",
    "- [intfloat/e5-mistral-7b-instruct](https://huggingface.co/intfloat/e5-mistral-7b-instruct) - 4096 dimensions, requires 14.5 GB RAM\n",
    "- [WhereIsAI/UAE-Large-V1](https://huggingface.co/WhereIsAI/UAE-Large-V1) - 1024 dimensions, requires 1.5 GB RAM\n",
    "- [Salesforce/SFR-Embedding-Mistral](https://huggingface.co/Salesforce/SFR-Embedding-Mistral) - consistently scores top, untested\n",
    "- [OpenAI/text-embedding-3-large](https://openai.com/blog/new-embedding-models-and-api-updates) - hosted by OpenAI, not open source\n",
    "- [OpenAI/text-embedding-ada-002](https://openai.com/blog/new-and-improved-embedding-model) - hosted by OpenAI, not open source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: Orin\n",
      "Python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:26:55) [GCC 12.3.0]\n",
      "PyTorch: 2.3.0a0+ebedce2\n",
      "CUDA: 12.2\n",
      "CUDNN: 8904\n"
     ]
    }
   ],
   "source": [
    "from argmap.helpers import printTorchDeviceVersion\n",
    "\n",
    "printTorchDeviceVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 23:37:31.029977 Initializing embedding model: WhereIsAI/UAE-Large-V1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name WhereIsAI/UAE-Large-V1. Creating a new one with MEAN pooling.\n",
      "CUDA Memory: 50.3 GB free, 1.2 GB allocated, 61.4 GB total\n",
      "CUDA Memory: 50.3 GB free, 1.2 GB allocated, 61.4 GB total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-19 23:37:33.498794 Embedding model initialized.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from argmap.helpers import ensureCUDAMemory, printCUDAMemory, loadEmbeddingModel\n",
    "\n",
    "if os.getenv(\"EMBED_MODEL_ID\") is None:\n",
    "    print(\"EMBED_MODEL_ID environment variable is required.\")\n",
    "    sys.exit(3)\n",
    "\n",
    "model = loadEmbeddingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and Store Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_embeddings(comments, model, show_progress_bar=False):\n",
    "    documents = comments.df.get_column('commentText').to_list()\n",
    "    embeddings = model.encode(documents, show_progress_bar=show_progress_bar)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-assembly.bowling-green: Loaded 896 comments from Parquet DataFrame.\n",
      "Topic: Improving Bowling Green / Warren County\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8858a7e235427e9f09078211f432d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-assembly.bowling-green: Saved 896 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "march-on.operation-marchin-orders: Loaded 2162 comments from Parquet DataFrame.\n",
      "Topic: Operation Marching Orders\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2cb18b927d49208ddfd9e5bfd0624d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "march-on.operation-marchin-orders: Saved 2162 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.biodiversity: Loaded 316 comments from Parquet DataFrame.\n",
      "Topic: Protecting and Restoring NZ's Biodiversity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95164ccc7bb4ddfb7eb9f0ed2426f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.biodiversity: Saved 316 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.freshwater: Loaded 80 comments from Parquet DataFrame.\n",
      "Topic: HiveMind - Freshwater Quality in NZ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf32c442e104a9db9a5a2c7c0e9852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.freshwater: Saved 80 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.taxes: Loaded 148 comments from Parquet DataFrame.\n",
      "Topic: Tax HiveMind Window\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b132dfc507914465a6fbe56a04ae411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.taxes: Saved 148 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.ubi: Loaded 71 comments from Parquet DataFrame.\n",
      "Topic: A Universal Basic Income for Aotearoa NZ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85baba39a1be4f51a1eb905b95b89dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.ubi: Saved 71 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "scoop-hivemind.affordable-housing: Loaded 165 comments from Parquet DataFrame.\n",
      "Topic: ScoopNZ Hivemind on affordable housing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc632545faf46e98dfee4e97a5912d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoop-hivemind.affordable-housing: Saved 165 comments with embeddings to Parquet DataFrame.\n",
      "\n",
      "ssis.land-bank-farmland.2rumnecbeh.2021-08-01: Loaded 297 comments from Parquet DataFrame.\n",
      "Topic: JOIN THE DISCUSSION BELOW: Land use and conservation in the San Juan Islands\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f2ad30b3ff42948cc4e5c1dd9efa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssis.land-bank-farmland.2rumnecbeh.2021-08-01: Saved 297 comments with embeddings to Parquet DataFrame.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from argmap.dataModel import Summary, Comments\n",
    "\n",
    "DATASETS = [\n",
    "    \"american-assembly.bowling-green\",\n",
    "    \"march-on.operation-marchin-orders\",\n",
    "    \"scoop-hivemind.biodiversity\",\n",
    "    \"scoop-hivemind.freshwater\",\n",
    "    \"scoop-hivemind.taxes\",\n",
    "    \"scoop-hivemind.ubi\",\n",
    "    \"scoop-hivemind.affordable-housing\",\n",
    "    \"ssis.land-bank-farmland.2rumnecbeh.2021-08-01\",\n",
    "]\n",
    "\n",
    "EMBED_MODEL_ID = os.getenv('EMBED_MODEL_ID')\n",
    "\n",
    "for dataset in DATASETS:\n",
    "\n",
    "    summary = Summary(dataset)\n",
    "    comments = Comments(dataset)\n",
    "\n",
    "    if os.path.exists(comments.filename):\n",
    "        comments.load_from_parquet()\n",
    "        print(f\"{dataset}: Loaded {comments.df.height} comments from Parquet DataFrame.\")\n",
    "    else:\n",
    "        comments.load_from_csv()\n",
    "        print(f\"{dataset}: Loaded {comments.df.height} comments from original dataset CSV.\")\n",
    "\n",
    "    print(f\"Topic: {summary.get('topic')}\")\n",
    "\n",
    "    embeddings = calculate_embeddings(comments, model, show_progress_bar=True)\n",
    "    comments.addColumns(pl.Series(embeddings).alias(f'embedding-{EMBED_MODEL_ID}'))\n",
    "    comments.save_to_parquet()\n",
    "    print(f\"{dataset}: Saved {comments.df.height} comments with embeddings to Parquet DataFrame.\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:argmap]",
   "language": "python",
   "name": "conda-env-argmap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
